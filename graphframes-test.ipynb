{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, array_contains, sum, collect_list, array, col, explode, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[2]\")\n",
    "    .appName(\"local-tests\")\n",
    "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "from graphframes import *\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"id1\", \"anid1\", None, \"userIDFA1\", \"SapphireId1\", 0.1),\n",
    "        (\"id2\", \"anid1\", \"AdId1\", None, None, 0.2),\n",
    "        (\"id3\", \"anid2\", \"AdId1\", None, \"SapphireId2\", 0.3),\n",
    "        (\"id4\", \"anid3\", None, None, \"SapphireId2\", 0.4),\n",
    "        (\"id5\", \"anid4\", None, \"userIDFA2\", None, 0.5),\n",
    "        (\"id6\", \"anid5\", None, \"userIDFA2\", \"SapphireId3\", 0.6),\n",
    "        (\"id7\", \"anid5\", None, \"userIDFA2\", \"SapphireId3\", 0.7),\n",
    "    ],\n",
    "    [\"id\", \"anid\", \"AdId\", \"userIDFA\", \"SapphireId\", \"Cashback\"],\n",
    ")\n",
    "\n",
    "id_cols = [\"anid\", \"AdId\", \"userIDFA\", \"SapphireId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt(\n",
    "    df, id_vars, value_vars, var_name=\"variable\", value_name=\"value\", dropna=False\n",
    "):\n",
    "    # Create an array of column names for the id variables\n",
    "    id_cols = [col(c) for c in id_vars]\n",
    "\n",
    "    # Create an array of column names for the value variables\n",
    "    value_cols = [\n",
    "        struct(lit(c).alias(var_name), col(c).alias(value_name)) for c in value_vars\n",
    "    ]\n",
    "\n",
    "    # Explode the value columns into rows\n",
    "    exploded_df = df.select(id_cols + [explode(array(value_cols)).alias(\"tmp\")])\n",
    "\n",
    "    # Extract the variable and value columns from the struct\n",
    "    result_df = exploded_df.select(\n",
    "        id_cols\n",
    "        + [\n",
    "            col(\"tmp\")[var_name].alias(var_name),\n",
    "            col(\"tmp\")[value_name].alias(value_name),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Drop null values if dropna is True\n",
    "    if dropna:\n",
    "        result_df = result_df.dropna()\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|         id|      Type|\n",
      "+-----------+----------+\n",
      "|      AdId1|      AdId|\n",
      "|      anid1|      anid|\n",
      "|SapphireId1|SapphireId|\n",
      "|      anid2|      anid|\n",
      "|  userIDFA1|  userIDFA|\n",
      "|SapphireId2|SapphireId|\n",
      "|  userIDFA2|  userIDFA|\n",
      "|      anid3|      anid|\n",
      "|SapphireId3|SapphireId|\n",
      "|      anid4|      anid|\n",
      "|      anid5|      anid|\n",
      "+-----------+----------+\n",
      "\n",
      "+-----------+-----------+---+--------+\n",
      "|        src|        dst| id|Cashback|\n",
      "+-----------+-----------+---+--------+\n",
      "|      anid1|  userIDFA1|id1|     0.1|\n",
      "|      anid1|SapphireId1|id1|     0.1|\n",
      "|  userIDFA1|      anid1|id1|     0.1|\n",
      "|  userIDFA1|SapphireId1|id1|     0.1|\n",
      "|SapphireId1|      anid1|id1|     0.1|\n",
      "|SapphireId1|  userIDFA1|id1|     0.1|\n",
      "|      anid1|      AdId1|id2|     0.2|\n",
      "|      AdId1|      anid1|id2|     0.2|\n",
      "|      anid2|      AdId1|id3|     0.3|\n",
      "|      anid2|SapphireId2|id3|     0.3|\n",
      "|      AdId1|      anid2|id3|     0.3|\n",
      "|      AdId1|SapphireId2|id3|     0.3|\n",
      "|SapphireId2|      anid2|id3|     0.3|\n",
      "|SapphireId2|      AdId1|id3|     0.3|\n",
      "|      anid3|SapphireId2|id4|     0.4|\n",
      "|SapphireId2|      anid3|id4|     0.4|\n",
      "|      anid4|  userIDFA2|id5|     0.5|\n",
      "|  userIDFA2|      anid4|id5|     0.5|\n",
      "|      anid5|  userIDFA2|id6|     0.6|\n",
      "|      anid5|SapphireId3|id6|     0.6|\n",
      "+-----------+-----------+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def createGraphFrame(df, id_vars, value_vars, src_col=\"src\", dst_col=\"dst\"):\n",
    "    melted_df = melt(\n",
    "        df, id_vars, value_vars, var_name=\"Type\", value_name=\"value\", dropna=True\n",
    "    )\n",
    "    src = melted_df.select(*id_vars, col(\"value\").alias(src_col)).alias(\"src\")\n",
    "    dst = melted_df.select(*id_vars, col(\"value\").alias(dst_col)).alias(\"dst\")\n",
    "    edges_df = (\n",
    "        src.join(dst, on=id_vars)\n",
    "        .where(col(src_col) != col(dst_col))\n",
    "        .select(src_col, dst_col, *id_vars)\n",
    "    )\n",
    "    v = melted_df.select(col(\"value\").alias(\"id\"), \"Type\").distinct()\n",
    "    g = GraphFrame(v, edges_df)\n",
    "    return g\n",
    "\n",
    "\n",
    "g = createGraphFrame(df, [\"id\", \"Cashback\"], id_cols)\n",
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\".spark_checkpoint\")\n",
    "type_id_to_component = g.connectedComponents()\n",
    "\n",
    "component_df_grouped = (\n",
    "    type_id_to_component.groupBy(\"component\").pivot(\"Type\").agg(collect_list(\"id\"))\n",
    ")\n",
    "component_df_grouped = component_df_grouped.toDF(\n",
    "    *[\"component_\" + c if c != \"component\" else c for c in component_df_grouped.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+--------------------+--------------------+------------------+---+-----+-----+---------+-----------+--------+\n",
      "|   component|component_AdId|component_SapphireId|      component_anid|component_userIDFA| id| anid| AdId| userIDFA| SapphireId|Cashback|\n",
      "+------------+--------------+--------------------+--------------------+------------------+---+-----+-----+---------+-----------+--------+\n",
      "|  8589934592|            []|       [SapphireId3]|      [anid4, anid5]|       [userIDFA2]|id6|anid5| null|userIDFA2|SapphireId3|     0.6|\n",
      "|  8589934592|            []|       [SapphireId3]|      [anid4, anid5]|       [userIDFA2]|id7|anid5| null|userIDFA2|SapphireId3|     0.7|\n",
      "|369367187456|       [AdId1]|[SapphireId1, Sap...|[anid1, anid2, an...|       [userIDFA1]|id1|anid1| null|userIDFA1|SapphireId1|     0.1|\n",
      "|369367187456|       [AdId1]|[SapphireId1, Sap...|[anid1, anid2, an...|       [userIDFA1]|id3|anid2|AdId1|     null|SapphireId2|     0.3|\n",
      "|369367187456|       [AdId1]|[SapphireId1, Sap...|[anid1, anid2, an...|       [userIDFA1]|id4|anid3| null|     null|SapphireId2|     0.4|\n",
      "+------------+--------------+--------------------+--------------------+------------------+---+-----+-----+---------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def join_component_with_transactions(component_df_grouped, transactions_df, id_cols):\n",
    "    # Join component_df_grouped with transactions_df on matching ids\n",
    "    for col in id_cols:\n",
    "        join_condition = array_contains(\n",
    "            component_df_grouped[\"component_\" + col], transactions_df[col]\n",
    "        )\n",
    "    joined_df = component_df_grouped.alias(\"component_df\").join(\n",
    "        transactions_df.alias(\"transactions_df\"), join_condition, \"left_outer\"\n",
    "    )\n",
    "    return joined_df\n",
    "\n",
    "\n",
    "test = join_component_with_transactions(component_df_grouped, df, id_cols)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_level_features = test.groupBy(\"component\").agg(\n",
    "    sum(col(\"Cashback\")).alias(\"totalCashback\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+--------------------+--------------------+------------------+------------------+\n",
      "|   component|component_AdId|component_SapphireId|      component_anid|component_userIDFA|     totalCashback|\n",
      "+------------+--------------+--------------------+--------------------+------------------+------------------+\n",
      "|  8589934592|            []|       [SapphireId3]|      [anid4, anid5]|       [userIDFA2]|1.2999999999999998|\n",
      "|369367187456|       [AdId1]|[SapphireId1, Sap...|[anid1, anid2, an...|       [userIDFA1]|               0.8|\n",
      "+------------+--------------+--------------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "component_df_grouped.join(component_level_features, on=\"component\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
